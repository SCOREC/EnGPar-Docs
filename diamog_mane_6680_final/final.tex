\documentclass[a4paper]{article}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{amsmath}
\geometry{margin=1in}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{titling}

\setlength{\droptitle}{-11em}

\title{EnGPar - Partitioning and Load Balancing for Relation Based Data}

\author{Gerrett Diamond}

\date{\today}

\begin{document}

\maketitle

\section{Introduction}
%TODO: rework into a full introduction and abstract
A main problem in parallel applications is ensuring a even distribution of load across all the processors. While some applications can naively distribute data evenly, many applications have complicated designs that require load balancing procedures that partition based on the computation and communication costs. For finite element programs that utilize unstructured meshes, there exists a complicated structure of computation costs that depend on where degrees of freedoms are defined and the type of shape functions being used. Thus any load balancing technique must offer a diverse set of procedures to target the different levels of imbalance relative to the finite element method being applied. To target the different load balancing requirements we propose utilizing an expanded graph structure, N-graph \cite{EnGPar2015proposal}, that can represent multiple levels of relations simultaneously coupled with a set of partitioning techniques and diffusive load balancing strategies.

\section{Related Works}

\subsection{Geometric Partitioning}
Some of the fastest and simpliest partitioning techniques are geometric partitioning algorithms that utilize coordinate information on the data and partition just based on the spatial distribution of the data. Some of these techniques include Recursive Coordinate Bisection and Recursive Inertial Bisection \cite{williamsRIB,TaylorRIB,chevalier2012load} which recursively partition the data by defining cut planes in space to create the parts. While these techniques are relitively fast and can partition the data well, the edge cut across parts is often poor and thus the communication costs tends to be quite high. Furthmore, there is no consideration given to multi-criteria partitioning for these techniques so there is no guarentee that the partitioning will be sufficient for finite element methods.

\subsection{Graph Partitioning}
The most common methods to partition relation-based data structures is utilizing a graph or hypergraph structure to represent the data followed by partitioning techniques that are performed on the structure. Some commonly used libraries to perform graph partitioning include ParMETIS \cite{parmetis4} and PT-Scotch \cite{scotch2009}. These algorithms globally partition the data targeting balancing the vertices of the graph in each part and the edge cut across parts. These algorithms tend to work well for simple relation structures but can fail when there are multiple criterias to be balanced simultaneously. For example when partitioning unstructured meshes, graph partitioning tends to have high mesh vertex imbalances which can be detrimental for finite element procedures that have degrees of freedom on the mesh vertices. \\
On top of graph partitioners there are also hypergraph partitioners that utilize hyperedges to better represent the communication costs between processors for highly interconnected relation-based data structures like unstructured meshes \cite{devine2002zoltan}. These techniques tend to decrease the overall edge cut and reduce the communication volume across parts. Like graph partitioning, hypergraph partitioning also suffer from having high imbalances of any entities in the data that are not represented as graph vertices. 

\subsection{Diffusive Load Balancing}
Typically less powerful but faster than graph partitioning techniques are diffusive load balancing methods which iteratively migrate data from high load parts to the lower loaded neighbors across part boundaries. These methods like ParMA \cite{Smith2015} allow techniques that can target different metrics as well as multiple criteras simultaneously which other methods cannot. These methods are often used as a routine to improve upon a partition as the migrations are only done locally between a part and its neighbors instead of the global partitioning seen in geometric and graph partitioning techniques.

\section{Methodology}
\subsection{Ngraph}
EnGPar interfaces to the differenct partitioning procedures through a graph abstraction called the N-Graph. Towards supporting a combination of (hyper)graph, geomertic and diffusive partitioning methods on relation-based data, the N-Graph is defined as $G^n(V,E_0,E_1,...,E_{n-1},[P_0,P_1,...,P_{n-1}])$ where:
\begin{itemize}
  \item $V$ atomic units $u_i$ of the domain $\omega$ which uniquely exist on one
    part such that $\omega = \bigcup_{\forall_i}u_i$, and 
  \item $E_i$ relations $e_i$ of type $i$ that represent either a tradiational edge between two vertices, $u$ and $v$, or a hyperedge which relate a set of vertices
  \item $P_i(e,v)$ pins in the case of hyperedges which represent the connection
    from $e$ to $v$ where $e \in E_i$ and $v \in V$.
\end{itemize}
Optionally, the vertices and edges may be assigned with weights to better control partitioning. Vertices may also have spacial relations in the form of a coordinate vector $c$.\\
Applications utilizing this abstraction define atomic domain entities as vertices in the N-Graph and at least one relation between them as the (hyper)edges. In this manner, applications may represent multiple relations of different sparsity and degree. For example the toplogy of an unstructured 3D mesh may be represented via vertices defined as mesh elements and a hyperedge type for each entity shared by adjacent elements. Figure \ref{fig:Mesh2Graph} depicts the mapping of an unstructured mesh (a) to a representation where mesh elements map to graph vertices and mesh vertices map to graph hyperedges (b) and a second mapping where mesh edges are mapped to a second edge type in the graph (c).

\subsection{Migration}


\subsection{Diffusive Balancer Framework}
In order to support continuously new methods of diffusive load balancing and new criterias and priorities, a general algorithm is defined for both ease of use and creation for future use of EnGPar. Algorithm \ref{alg:balancer} lists pseudocode for the overall design of the balancer. For each diffusive technique being implemented five methods need to be defined:
\begin{itemize}
  \item $makeSides$\\
    Each process calculates the length of the part boundaries to all neighbors.
  \item $makeVtxWeights$ \\
    Each process calculates the weight of its own vertices and shares with each neighboring process.
  \item $makeEdgeWeights$ \\
    Each process calculates the weight of its own edges and shares with each neighboring process.
  \item $makeTargets$\\
    Each process calculates the amount of weight to send to each of its neighbors.
  \item $makeSelector$\\
    Makes a migration plan of the vertices to send to neighboring processes based on the iteration queue and amount of weight being sent.
\end{itemize}
Further operation control is also possible through changing the $createIterationQueue$ function which controls the order that graph vertices are iterated when selecting for migration. Stagnation detection is utilized to ensure that the balancer ends after no more improvements are found rather than completing any further unproductive iterations.

\begin{algorithm}
\caption{Diffusive balancer design}\label{alg:balancer}
\begin{algorithmic}
  \label{alg:balancer}
  \Procedure{runStep}{Ngraph g}
  \State sides = makeSides(g)
  \State vtxWeights = makeVtxWeights(g,sides)
  \For {each edge type i}
  \State edgeWeights[i] = makeEdgeWeights(g,sides,i)
  \EndFor
  \State targets = makeTargets(g,sides,vtxWeights,edgeWeights)
  \State pq = createIterationQueue(g)
  \State selector = makeSelector(pq)
  \For {increasing cavity size,cavSize}
  \State plan $\leftarrow$ selector.select(targets,cavSize)
  \EndFor
  \State g.migrate(plan)
  \State Update Stagnation Detection
  \EndProcedure
  \Procedure{balance}{Ngraph g}
  \State iter=0
  \For {iter=0 to maxIter}
  \State runstep(g)
  \If {balance has stagnated or g is sufficiently balanced}
  \State return
  \EndIf
  \EndFor
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Vertex Balancer}
As proof of concept a simple diffusive vertex balancer was implemented off of this design. The vertex balancer targets balancing the sum of the weights of the vertices in the graph. To do so we implement the five basic functions mentioned previously as follows. The $makeSides$ function has each part compute $s_i$ which is the number of (hyper)edges that are cut between this part and part $i$. This way each part knows which parts are its neighbors and has a metric representing the length of the boundary to the part. Second is the $makeVtxWeights$ function. This function has each part compute the sum of the weights of the local vertices and shares this value with each of its neighbors. Thus each part has a weight, $w_i$, that corresponds to each $s_i>0$. The $makeEdgeWeights$ function does nothing for this balancer since it only prioritizes the vertex weight. The $makeTargets$ function takes each neighboring weight and if the part's weight is greater than the neighbor's weight than it computes the amount of weight to send to that part in this iteration. This value is equal to 
$$(w-w_i)*\dfrac{s_i}{\sum{s_i}}*\text{factor}$$
where the factor is some parameter that controls the step size of each iteration. The final piece, $makeSelector$, is a selection procedure that traverses the given iteration queue and selects cavities that are shared between a part and a target neighboring part. For now the selector is kept simple for testing cases, but in future iterations will include capabilities such as canceling some parts of the migration plan to account for multi-criteria or improving some metric for specific load balancing goals.

\subsection{Extending to Multi-Criteria Balancing}
In order to advance to multi-criteria load balancing we have to expand some of the functionality created in the vertex balancer. The $makeSides$ and $makeVtxWeights$ functions will be unchanged since they act similarly. However now the $makeEdgeWeights$ function will be used to calculate the weights of each edge type that is being targeted. The $makeTarget$ function will have to be altered to take into account the edge weights given by the $makeEdgeWeights$ function as well as look at the priorities of the edge types and vertices given by the user. The biggest change required is to the selector which has to take into account the weights of all edge types being balanced and make appropriate changes to the migration plan to ensure that the partition improves in each iteration. 

\section{Experiments}

\section{Results}

\section{Future Work}
As detailed earlier, for multi-criteria load balancing there is much work to be done to add functionality to the selector in order to properly balance the range of priorities any given user could have. Continuing on that the selector will need to have the ability to correct the plan by cancelling portions of the migration plan to best balance based on the different criteria. \\
Another portion that can have a major impact on the quality of partitioning for these diffusive methods is the order in which the vertices are iterated over. The current method is iterating blindly over how the vertices are stored in memory with no regards to the overall structure of the part. While this will result in balancing the vertices, for some instances the parts can become elongated and result in large diameters. In ParMA \cite{Smith2015}, the iteration follows a graph distance based metric which prioritizes mesh elements that are further away from the part centroid. This method results in rounder parts and smoother part boundaries as well as reducing the diameter of the part. Further work will go into implementing this method into EnGPar and also exploring other options and what metrics are effected by the order of iteration.


\section{Conclusion}


\newpage \bibliographystyle{plain}
\bibliography{references}
%\bibliography{scorec-refs/partition,scorec-refs/meshdb,scorec-refs/hardware,scorec-refs/io,scorec-refs/frameworks,scorec-refs/cr,scorec-refs/fem,scorec-refs/meshgen,scorec-refs/msgpass,references}

\end{document}
